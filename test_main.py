import os
import hashlib
import json
import io
import streamlit as st
from dotenv import load_dotenv
from PIL import Image
from ultralytics import YOLO
# LangChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate

# ======================================================
# ‚öôÔ∏è C·∫•u h√¨nh m√¥i tr∆∞·ªùng
# ======================================================
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y API key trong file .env")
    st.stop()

DATA_PATH = "text.txt"
FAISS_PATH = "faiss_index"
HASH_PATH = os.path.join(FAISS_PATH, "data_hash.json")

# ======================================================
# üîπ H√†m ti·ªán √≠ch
# ======================================================
def compute_md5(text):
    return hashlib.md5(text.encode("utf-8")).hexdigest()

def load_text_database(path):
    """ƒê·ªçc to√†n b·ªô text.txt v√† t√°ch theo b√†i thu·ªëc (m·ªói b√†i c√°ch nhau 1 d√≤ng tr·ªëng)."""
    with open(path, "r", encoding="utf-8") as f:
        content = f.read()
    return [x.strip() for x in content.split("\n\n") if x.strip()]

# ======================================================
# üîπ FAISS loader/update
# ======================================================
def load_or_update_faiss(data_path=DATA_PATH, db_path=FAISS_PATH):
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    os.makedirs(db_path, exist_ok=True)

    with open(data_path, "r", encoding="utf-8") as f:
        full_text = f.read()

    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    chunks = splitter.split_text(full_text)

    old_hashes = {}
    if os.path.exists(HASH_PATH):
        with open(HASH_PATH, "r", encoding="utf-8") as f:
            old_hashes = json.load(f)

    new_chunks = []
    new_hashes = {}
    for chunk in chunks:
        h = compute_md5(chunk)
        new_hashes[h] = True
        if h not in old_hashes:
            new_chunks.append(chunk)

    if not os.path.exists(os.path.join(db_path, "index.faiss")):
        st.info("üß† T·∫°o m·ªõi FAISS database...")
        vector_store = FAISS.from_texts(chunks, embedding=embeddings)
    else:
        vector_store = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
        if new_chunks:
            st.info(f"üîÑ Ph√°t hi·ªán {len(new_chunks)} ƒëo·∫°n m·ªõi ‚Üí c·∫≠p nh·∫≠t FAISS...")
            vector_store.add_texts(new_chunks)
        else:
            st.success("‚úÖ Kh√¥ng c√≥ thay ƒë·ªïi m·ªõi trong c∆° s·ªü d·ªØ li·ªáu.")

    vector_store.save_local(db_path)
    with open(HASH_PATH, "w", encoding="utf-8") as f:
        json.dump(new_hashes, f, ensure_ascii=False, indent=2)

    st.success("‚úÖ FAISS ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.")
    return vector_store

# ======================================================
# üîπ H√†m t√¨m b√†i thu·ªëc ch·ª©a nhi·ªÅu v·ªã tr√πng nh·∫•t
# ======================================================
def find_best_matches(herb_list, database, max_return=5):
    """
    Tr·∫£ v·ªÅ c√°c b√†i thu·ªëc c√≥ nhi·ªÅu v·ªã tr√πng nh·∫•t.
    N·∫øu kh√¥ng c√≥ b√†i n√†o ch·ª©a to√†n b·ªô, gi·∫£m d·∫ßn.
    """
    herbs = [h.strip() for h in herb_list.split(",") if h.strip()]
    matched = []
    for entry in database:
        count = sum(1 for h in herbs if h in entry)
        if count > 0:
            matched.append((entry, count))

    matched.sort(key=lambda x: x[1], reverse=True)

    if not matched:
        return []

    # ch·ªçn top b√†i thu·ªëc c√≥ s·ªë v·ªã tr√πng cao nh·∫•t ho·∫∑c gi·∫£m d·∫ßn
    top_count = matched[0][1]
    filtered = [x for x in matched if x[1] == top_count]

    # n·∫øu kh√¥ng ƒë·ªß, th√™m b√†i c√≥ √≠t h∆°n
    if len(filtered) < max_return:
        filtered += [x for x in matched if x[1] < top_count][: max_return - len(filtered)]

    return filtered[:max_return]

# ======================================================
# üîπ RAG QA Chain
# ======================================================
def create_qa_chain(vector_store, k=5):
    retriever = vector_store.as_retriever(search_kwargs={"k": k})
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.3)

    prompt_template = """
    B·∫°n l√† **chuy√™n gia y h·ªçc c·ªï truy·ªÅn Vi·ªát Nam**, am hi·ªÉu d∆∞·ª£c li·ªáu v√† b√†i thu·ªëc.
    H√£y ƒë·ªçc c√°c b√†i thu·ªëc trong d·ªØ li·ªáu sau v√† ƒë∆∞a ra c√¢u tr·∫£ l·ªùi theo y√™u c·∫ßu.

    -----------------
    C√°c b√†i thu·ªëc ƒë∆∞·ª£c ch·ªçn t·ª´ c∆° s·ªü d·ªØ li·ªáu (∆∞u ti√™n nhi·ªÅu v·ªã tr√πng kh·ªõp nh·∫•t):
    {top_recipes}
    -----------------
    C√¢u h·ªèi ng∆∞·ªùi d√πng: {question}
    -----------------
    H√£y:
    1. Gi·∫£i th√≠ch ng·∫Øn g·ªçn (2‚Äì3 c√¢u t·ªïng qu√°t).
    2. Li·ªát k√™ chi ti·∫øt c√°c b√†i thu·ªëc li√™n quan:
       - **T√™n b√†i thu·ªëc:** ...
       - **Th√†nh ph·∫ßn:** ...
       - **C√°ch d√πng:** ...
       - **Ch·ªâ ƒë·ªãnh:** ...
    3. N·∫øu nhi·ªÅu b√†i thu·ªëc, s·∫Øp x·∫øp theo ƒë·ªô ph√π h·ª£p cao nh·∫•t.
    4. N·∫øu kh√¥ng c√≥ th√¥ng tin, n√≥i: "Kh√¥ng t√¨m th·∫•y trong c∆° s·ªü d·ªØ li·ªáu."
    5. Cu·ªëi c√πng ghi ch√∫: *(Th√¥ng tin ch·ªâ mang t√≠nh tham kh·∫£o, kh√¥ng thay th·∫ø t∆∞ v·∫•n y khoa).*
    -----------------
    Tr·∫£ l·ªùi:
    """

    prompt = PromptTemplate(
        input_variables=["top_recipes", "question"],
        template=prompt_template
    )

    def ask_with_database(top_recipes, user_question):
        context = "\n\n".join([r[0] for r in top_recipes])
        final_prompt = prompt.format(top_recipes=context, question=user_question)
        response = llm.invoke(final_prompt)
        return response.content

    return ask_with_database

# ======================================================
# üîπ Giao di·ªán Streamlit
# ======================================================
def main():
    st.set_page_config(page_title="üåø Chatbot Thu·ªëc B·∫Øc", page_icon="üåø", layout="wide")
    st.title("üåø Chatbot Y h·ªçc C·ªï truy·ªÅn ‚Äì Nh·∫≠n di·ªán & G·ª£i √Ω b√†i thu·ªëc")

    # 1Ô∏è‚É£ Kh·ªüi t·∫°o database
    if not os.path.exists(DATA_PATH):
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file {DATA_PATH}. H√£y ƒë·∫∑t n√≥ c√πng th∆∞ m·ª•c ·ª©ng d·ª•ng.")
        st.stop()

    vector_store = load_or_update_faiss(DATA_PATH, FAISS_PATH)
    text_database = load_text_database(DATA_PATH)

    # 2Ô∏è‚É£ Sidebar
    st.sidebar.header("‚öôÔ∏è C√†i ƒë·∫∑t")
    k = st.sidebar.slider("üî¢ S·ªë ƒëo·∫°n FAISS (k):", 1, 10, 5)

    st.sidebar.header("üì∏ Nh·∫≠n di·ªán v·ªã thu·ªëc")
    uploaded_files = st.sidebar.file_uploader(
        "T·∫£i ·∫£nh v·ªã thu·ªëc (PNG, JPG, JPEG, BMP):",
        accept_multiple_files=True,
        type=["png", "jpg", "jpeg", "bmp"]
    )

    @st.cache_resource
    def load_recognition_model():
        return YOLO('recog.pt')

    recognition_model = load_recognition_model()

    # 3Ô∏è‚É£ H·ªèi vƒÉn b·∫£n
    st.markdown("### üí¨ C√¢u h·ªèi")
    user_question = st.text_input("V√≠ d·ª•: 'B√†i thu·ªëc n√†o tr·ªã m·∫•t ng·ªß c√≥ v·ªã k·ª∑ t·ª≠ v√† ho√†ng k·ª≥?'")

    # 4Ô∏è‚É£ Nh·∫≠n di·ªán thu·ªëc
    if st.sidebar.button("Nh·∫≠n di·ªán & G·ª£i √Ω b√†i thu·ªëc"):
        if not uploaded_files:
            st.sidebar.error("Vui l√≤ng t·∫£i √≠t nh·∫•t m·ªôt ·∫£nh.")
            return

        detected_herbs = []
        for file in uploaded_files:
            image = Image.open(io.BytesIO(file.read()))
            st.image(image, caption=f"·∫¢nh: {file.name}", use_container_width=True)

            with st.spinner("ƒêang nh·∫≠n di·ªán v·ªã thu·ªëc..."):
                results = recognition_model.predict(image)
                names = recognition_model.names
                for r in results:
                    for box in r.boxes:
                        cls = int(box.cls)
                        name = names[cls]
                        if name not in detected_herbs:
                            detected_herbs.append(name)
                            st.success(f"Ph√°t hi·ªán: **{name}**")

        if not detected_herbs:
            st.warning("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c v·ªã thu·ªëc n√†o.")
            return

        herb_list = ", ".join(detected_herbs)
        st.markdown("### üßæ V·ªã thu·ªëc nh·∫≠n di·ªán:")
        st.write(herb_list)

        # 5Ô∏è‚É£ Map database ƒë·ªÉ ch·ªçn b√†i ph√π h·ª£p nh·∫•t
        matched_recipes = find_best_matches(herb_list, text_database)
        if not matched_recipes:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y b√†i thu·ªëc n√†o trong c∆° s·ªü d·ªØ li·ªáu.")
            return

        st.markdown("### üìö C√°c b√†i thu·ªëc ph√π h·ª£p nh·∫•t (l·ªçc theo s·ªë v·ªã tr√πng):")
        for i, (text, count) in enumerate(matched_recipes, 1):
            st.markdown(f"{i}. ({count} v·ªã tr√πng)\n{text}\n---")

        # 6Ô∏è‚É£ G·ªçi GPT ƒë·ªÉ tr·∫£ l·ªùi t·ª± nhi√™n h∆°n
        qa_chain = create_qa_chain(vector_store, k=k)
        st.markdown("### üí¨ G·ª£i √Ω t·ªïng h·ª£p:")
        answer = qa_chain(matched_recipes, user_question)
        st.markdown(answer)

# üöÄ Run
if __name__ == "__main__":
    main()
