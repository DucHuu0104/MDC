import os
import hashlib
import json
import io
import streamlit as st
from dotenv import load_dotenv
from PIL import Image

# LangChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
#from your_module import load_or_update_faiss, create_qa_chain, MedicineRecognitionModel
# ======================================================
# ğŸ” Giáº£ Ä‘á»‹nh báº¡n cÃ³ sáºµn model nháº­n dáº¡ng thuá»‘c
# recognition_model.py
# class MedicineRecognitionModel:
#     def __init__(self, model_path): ...
#     def predict(self, image): return "HoÃ ng ká»³"
# ======================================================

# Load API key
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("âŒ KhÃ´ng tÃ¬m tháº¥y API key trong file .env")
    st.stop()

# Cáº¥u hÃ¬nh
DATA_PATH = "text.txt"
FAISS_PATH = "faiss_index"
HASH_PATH = os.path.join(FAISS_PATH, "data_hash.json")

# =============================
# ğŸ”¹ HÃ m tiá»‡n Ã­ch
# =============================
def compute_md5(text):
    return hashlib.md5(text.encode("utf-8")).hexdigest()

# =============================
# ğŸ”¹ FAISS loader/update
# =============================
def load_or_update_faiss(data_path=DATA_PATH, db_path=FAISS_PATH):
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    os.makedirs(db_path, exist_ok=True)

    with open(data_path, "r", encoding="utf-8") as f:
        full_text = f.read()

    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    chunks = splitter.split_text(full_text)

    old_hashes = {}
    if os.path.exists(HASH_PATH):
        with open(HASH_PATH, "r", encoding="utf-8") as f:
            old_hashes = json.load(f)

    new_chunks = []
    new_hashes = {}
    for chunk in chunks:
        h = compute_md5(chunk)
        new_hashes[h] = True
        if h not in old_hashes:
            new_chunks.append(chunk)

    if not os.path.exists(os.path.join(db_path, "index.faiss")):
        st.info("ğŸ§  Táº¡o má»›i FAISS database...")
        vector_store = FAISS.from_texts(chunks, embedding=embeddings)
    else:
        vector_store = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
        if new_chunks:
            st.info(f"ğŸ”„ PhÃ¡t hiá»‡n {len(new_chunks)} Ä‘oáº¡n má»›i â†’ cáº­p nháº­t FAISS...")
            vector_store.add_texts(new_chunks)
        else:
            st.success("âœ… KhÃ´ng cÃ³ thay Ä‘á»•i má»›i trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.")

    vector_store.save_local(db_path)
    with open(HASH_PATH, "w", encoding="utf-8") as f:
        json.dump(new_hashes, f, ensure_ascii=False, indent=2)

    st.success("âœ… FAISS Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t.")
    return vector_store

# =============================
# ğŸ”¹ RAG QA Chain
# =============================
def create_qa_chain(vector_store):
    retriever = vector_store.as_retriever(search_kwargs={"k": 5})
    prompt_template = """
    Báº¡n lÃ  má»™t **chuyÃªn gia y há»c cá»• truyá»n Viá»‡t Nam** am hiá»ƒu dÆ°á»£c liá»‡u vÃ  bÃ i thuá»‘c báº¯c.
    Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘á»c ká»¹ ngá»¯ cáº£nh vÃ  tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng dá»±a trÃªn thÃ´ng tin cÃ³ trong Ä‘Ã³.

    ğŸ”¹ Quy táº¯c tráº£ lá»i:
    1. Giáº£i thÃ­ch ngáº¯n gá»n (2â€“3 cÃ¢u tá»•ng quÃ¡t).
    2. Liá»‡t kÃª chi tiáº¿t cÃ¡c **bÃ i thuá»‘c** liÃªn quan (náº¿u cÃ³):
       - **TÃªn bÃ i thuá»‘c:** ...
       - **ThÃ nh pháº§n:** ...
       - **CÃ¡ch dÃ¹ng:** ...
       - **Chá»‰ Ä‘á»‹nh:** ...
    3. Náº¿u cÃ³ nhiá»u bÃ i thuá»‘c, sáº¯p xáº¿p theo Ä‘á»™ phÃ¹ há»£p cao nháº¥t.
    4. Náº¿u khÃ´ng tÃ¬m tháº¥y, tráº£ lá»i: "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin trong tÃ i liá»‡u."
    5. Cuá»‘i cÃ¹ng, thÃªm ghi chÃº: *(ThÃ´ng tin chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng thay tháº¿ tÆ° váº¥n y khoa).*

    -----------------
    Ngá»¯ cáº£nh: {context}
    CÃ¢u há»i: {question}
    -----------------
    Tráº£ lá»i:
    """

    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template=prompt_template
    )

    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.3)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )

    return qa_chain

# =============================
# ğŸ”¹ Giao diá»‡n Streamlit
# =============================
def main():
    st.set_page_config(page_title="ğŸŒ¿ Chatbot Thuá»‘c Báº¯c", page_icon="ğŸŒ¿", layout="wide")
    st.title("ğŸŒ¿ Chatbot Y há»c Cá»• truyá»n â€“ Nháº­n diá»‡n & Gá»£i Ã½ bÃ i thuá»‘c")

    # 1ï¸âƒ£ Khá»Ÿi táº¡o cÆ¡ sá»Ÿ dá»¯ liá»‡u
    if not os.path.exists(DATA_PATH):
        st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {DATA_PATH}. HÃ£y Ä‘áº·t nÃ³ cÃ¹ng thÆ° má»¥c á»©ng dá»¥ng.")
        st.stop()

    st.info("ğŸ“‚ Äang táº£i hoáº·c cáº­p nháº­t FAISS database tá»« text.txt...")
    vector_store = load_or_update_faiss(DATA_PATH, FAISS_PATH)

    # 2ï¸âƒ£ Sidebar: Nháº­p áº£nh Ä‘á»ƒ nháº­n diá»‡n thuá»‘c
    st.sidebar.header("ğŸ“¸ Nháº­n diá»‡n vá»‹ thuá»‘c")
    uploaded_files = st.sidebar.file_uploader(
        "Táº£i áº£nh vá»‹ thuá»‘c (PNG, JPG, JPEG, BMP):",
        accept_multiple_files=True,
        type=["png", "jpg", "jpeg", "bmp"]
    )

    # 3ï¸âƒ£ Khá»Ÿi táº¡o model nháº­n dáº¡ng thuá»‘c (cache Ä‘á»ƒ tÄƒng tá»‘c)
    @st.cache_resource
    def load_recognition_model():
        return MedicineRecognitionModel("model/thuoc_recognition.pth")

    recognition_model = load_recognition_model()

    # 4ï¸âƒ£ Nháº­p cÃ¢u há»i vÄƒn báº£n
    st.markdown("### ğŸ’¬ Há»i trá»±c tiáº¿p vá» bÃ i thuá»‘c / triá»‡u chá»©ng")
    user_question = st.text_input("VÃ­ dá»¥: 'BÃ i thuá»‘c nÃ o trá»‹ máº¥t ngá»§ cÃ³ vá»‹ ká»· tá»­ vÃ  hoÃ ng ká»³?'")

    if user_question:
        with st.spinner("ğŸ§˜â€â™‚ï¸ Äang tra cá»©u bÃ i thuá»‘c..."):
            qa_chain = create_qa_chain(vector_store)
            result = qa_chain({"query": user_question})

        st.success("âœ… HoÃ n táº¥t.")
        st.markdown("### ğŸ§  Káº¿t quáº£:")
        st.markdown(result["result"])

    # 5ï¸âƒ£ Nháº­n dáº¡ng thuá»‘c tá»« áº£nh
    st.markdown("---")
    st.markdown("### ğŸ§ª Káº¿t quáº£ nháº­n diá»‡n thuá»‘c")

    if st.sidebar.button("ğŸ” Nháº­n diá»‡n & Gá»£i Ã½ bÃ i thuá»‘c"):
        if not uploaded_files:
            st.sidebar.error("âŒ Vui lÃ²ng táº£i Ã­t nháº¥t má»™t áº£nh.")
        else:
            detected_labels = []

            for file in uploaded_files:
                image = Image.open(io.BytesIO(file.read()))
                st.image(image, caption=f"áº¢nh: {file.name}", use_column_width=True)

                with st.spinner("ğŸ” Äang nháº­n diá»‡n vá»‹ thuá»‘c..."):
                    label = recognition_model.predict(image)
                    detected_labels.append(label)
                    st.success(f"âœ… PhÃ¡t hiá»‡n: **{label}**")

            if detected_labels:
                st.markdown("### ğŸ§¾ Káº¿t quáº£ nháº­n diá»‡n:")
                st.write(", ".join(detected_labels))

                # ğŸ” Tá»± Ä‘á»™ng truy váº¥n RAG Ä‘á»ƒ gá»£i Ã½ bÃ i thuá»‘c
                st.markdown("### ğŸ’¬ Gá»£i Ã½ bÃ i thuá»‘c liÃªn quan:")
                query = f"CÃ¡c bÃ i thuá»‘c cÃ³ chá»©a: {', '.join(detected_labels)}"
                qa_chain = create_qa_chain(vector_store)
                result = qa_chain({"query": query})
                st.markdown(result["result"])

# ğŸš€ Run app
if __name__ == "__main__":
    main()

